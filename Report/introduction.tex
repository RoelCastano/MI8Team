\section{Introduction}

As technology becomes part of all aspects of human nature and new trends such as the internet of things connect everyday objects to the internet, the amount of data stored in the digital universe has been growing at an outstanding rate. Consequently, processing and analysing these data sets has become increasingly difficult and techniques have been developed in the fields of machine learning, big data, and others to facilitate the use of information. \\
One of the many problems that arises from this growth of digital capacity is retrieving information from databases in a form that is useful to the users. Simply retrieving relevant information is not enough, since it can span a significant amount of data. We can see examples of this with search engines, recommender systems, and bioinformatics, where it is necessary to provide to users the relevant data based on relevance to a certain query and sort it accordingly. The Learning to Rank algorithm is design to solve this issue by taking into account multiple features which influence the relevance of each element and extensive research has been done to improve it in the last decade. \\
One interesting case where Learning to Rank (L2R) could be applied to is in extracting the value of certain links in Wikipedia articles to help users better navigate the encyclopaedia and prevent overlinking of articles. Wikipedia is an internet encyclopaedia with more than 38 million articles in over 250 different languages of semi-structured information. It is also the most popular wiki-based website, and is ranked by Alexa as the \#6 most popular website in the internet. It allows the collaborative modification of its articles by the users, which is one of the main reasons Wikipedia has grown to such an impressive size. \\
Being ``the free encyclopedia that anyone can edit'' has many advantages and disadvantages, and one of the disadvantages is, as mentioned before, Overlinking. As mentioned in a study by Ashwin Paranjape et al. \cite{paranjape}:  ``in the English Wikipedia, of all the 800,000 links added ... in February 2015, the majority (66\%) were not clicked even a single time in March 2015, and among the rest, most links were clicked only very rarely''. Since most of the editing of articles is done manually, finding and removing useless links to other articles is hard to do and editors do not focus on removing them. In this article, we would like to approach this problem by predicting the most valuable links for the users considering multiple features of the articles in question and weighting their importance. Given this case, we would like answer the following questions.
\begin{itemize}
\item Which features of the articles influence the value of a links the most?
\item How could the features for the L2R algorithm be weighted for maximum effectiveness?
\fxnote{Which would be relevant problems/questions?}
\end{itemize}
